{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2ubfiGFwzUct",
        "outputId": "103ae1df-63b2-4369-a2af-bd5d564124ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import statsmodels.formula.api as smf\n",
        "from data_load import make_df\n",
        "from Sup_Models import add_k, process_dataframe, svm_model, rf_model, logistic_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "source = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XqoNpaN-vYUx",
        "outputId": "a77b90f0-a877-4584-d3cf-4d16730af478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1980000 entries, 0 to 1979999\n",
            "Data columns (total 30 columns):\n",
            " #   Column      Dtype  \n",
            "---  ------      -----  \n",
            " 0   k           int64  \n",
            " 1   Class       object \n",
            " 2   Replicate   int64  \n",
            " 3   alpha_1_1   float64\n",
            " 4   alpha_1_2   float64\n",
            " 5   alpha_1_3   float64\n",
            " 6   alpha_2_1   float64\n",
            " 7   alpha_2_2   float64\n",
            " 8   alpha_2_3   float64\n",
            " 9   alpha_3_1   float64\n",
            " 10  alpha_3_2   float64\n",
            " 11  alpha_3_3   float64\n",
            " 12  pi_1_1      float64\n",
            " 13  pi_1_2      float64\n",
            " 14  pi_1_3      float64\n",
            " 15  pi_2_1      float64\n",
            " 16  pi_2_2      float64\n",
            " 17  pi_2_3      float64\n",
            " 18  pi_3_1      float64\n",
            " 19  pi_3_2      float64\n",
            " 20  pi_3_3      float64\n",
            " 21  pihat_12_1  float64\n",
            " 22  pihat_12_2  float64\n",
            " 23  pihat_12_3  float64\n",
            " 24  pihat_13_1  float64\n",
            " 25  pihat_13_2  float64\n",
            " 26  pihat_13_3  float64\n",
            " 27  pihat_23_1  float64\n",
            " 28  pihat_23_2  float64\n",
            " 29  pihat_23_3  float64\n",
            "dtypes: float64(27), int64(2), object(1)\n",
            "memory usage: 453.2+ MB\n",
            "None\n",
            "DataFrame Head:\n",
            "     k Class  Replicate  alpha_1_1  alpha_1_2  alpha_1_3  alpha_2_1  \\\n",
            "0  174     D        422    1.67643   0.165244   0.004873    1.65929   \n",
            "1  165     B        568    1.61819   0.183821   0.005080    1.60897   \n",
            "2   46     D        935    1.51567   0.173498   0.004984    1.51598   \n",
            "3  104     B       1066    1.56687   0.180586   0.005148    1.56836   \n",
            "4  106     B       1616    1.56959   0.182296   0.005077    1.57122   \n",
            "\n",
            "   alpha_2_2  alpha_2_3  alpha_3_1  ...    pi_3_3  pihat_12_1  pihat_12_2  \\\n",
            "0   0.172405   0.004977    1.66936  ...  0.001825    0.023858    0.006562   \n",
            "1   0.190646   0.005173    1.62316  ...  0.003163    0.077745    0.040300   \n",
            "2   0.175302   0.005010    1.51432  ...  0.001002    0.031700    0.004122   \n",
            "3   0.183883   0.005195    1.57999  ...  0.002590    0.063519    0.023817   \n",
            "4   0.183429   0.005093    1.57209  ...  0.002469    0.065477    0.025114   \n",
            "\n",
            "   pihat_12_3  pihat_13_1  pihat_13_2  pihat_13_3  pihat_23_1  pihat_23_2  \\\n",
            "0    0.000971    0.025631    0.006699    0.000981    0.055770    0.023845   \n",
            "1    0.002379    0.016925    0.005860    0.000907    0.014410    0.004442   \n",
            "2    0.000768    0.030677    0.003557    0.000714    0.045439    0.008215   \n",
            "3    0.001870    0.020952    0.003810    0.000748    0.024163    0.005383   \n",
            "4    0.001884    0.021184    0.003893    0.000742    0.021316    0.004480   \n",
            "\n",
            "   pihat_23_3  \n",
            "0    0.001851  \n",
            "1    0.000790  \n",
            "2    0.001084  \n",
            "3    0.000889  \n",
            "4    0.000796  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "### STEP 1: LOAD AND PREPROCESS DATAFRAMES\n",
        "#   make_df uses the numerical codes below to generate the needed dataframe:\n",
        "\n",
        "'''\n",
        "{\n",
        "  1: raw_df = NON-vectorized and NON-standardized df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  2: repvec_df = vectorized and NON-standardized df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  3: raw_df_mu = NON-vectorized and NON-standardized df of only first stastical moment (mean),\n",
        "\n",
        "  4: repvec_df_mu = vectorized and NON-standardized df of only first stastical moment (mean),\n",
        "\n",
        "  5: repvec_df_SS = vectorized and standardized (StandardScaler method) df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  6: repvec_df_L2 = vectorized and standardized (L2 normalization) df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  7: repvec_df_mu_SS = vectorized and standardized (StandardScaler method) df of only first stastical moment (mean),\n",
        "\n",
        "  8: repvec_df_mu_L2 = vectorized and standardized (L2 normalization) df of only first stastical moment (mean),\n",
        "\n",
        "  9: raw_df_SS = NON-vectorized and standardized (StandardScaler method) df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  10: raw_df_L2 = NON-vectorized and standardized (L2 normalization) df of all statistical moments (mean, var, SE),\n",
        "\n",
        "  11: raw_df_mu_SS = NON-vectorized and standardized (StandardScaler method) df of only first stastical moment (mean),\n",
        "\n",
        "  12: raw_df_mu_L2 = NON-vectorized and standardized (L2 normalization) df of only first stastical moment (mean),\n",
        "}\n",
        "'''\n",
        "\n",
        "###\n",
        "df = make_df(source, code=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 2: CONVERT DF TO FEATURE AND TARGET MATRICES AND CONDUCT AN 80/20 TRAINING/TEST SPLIT\n",
        "\n",
        "###\n",
        "\n",
        "X, Y = process_dataframe(df)\n",
        "# Split the X and Y matrices into training and test splits (80/20)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "98i0hOBHCf_M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "xm2KRWEXf0qA",
        "outputId": "76fa451c-b070-4e51-a3a7-e40f683cf68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.22%\n",
            "Number of features: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'endswith'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f1e8df150d58>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Sup_Models.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mimportant_features_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfluence_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mmapped_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_array_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMost Important Features and Their Influence Percentage:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Sup_Models.py\u001b[0m in \u001b[0;36mmap_array_elements\u001b[0;34m(array, len_features)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of features:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Fallback for len_features <= 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     result = [\n",
            "\u001b[0;32m/content/Sup_Models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of features:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Fallback for len_features <= 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     result = [\n",
            "\u001b[0;32m/content/Sup_Models.py\u001b[0m in \u001b[0;36mmap_string\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"mean of {s[:-2]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'endswith'"
          ]
        }
      ],
      "source": [
        "### STEP 3: CONDUCT MULTINOMIAL LOGISTIC REGRESSION; OUTPUT ACCURACY ON TEST SET\n",
        "\n",
        "###\n",
        "\n",
        "logistic_regression(X_train, Y_train, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 4: CONDUCT SVM USING LINEAR, RBF, AND POLYNOMIAL KERNELS; OUTPUT ACCURACY ON TEST SET\n",
        "\n",
        "###\n",
        "\n",
        "svm_model(X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "id": "K81wh-csDGNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 5: CONDUCT RANDOM FOREST REGRESSION; OUTPUT ACCURACY ON TEST SET\n",
        "\n",
        "###\n",
        "\n",
        "rf_model(X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "id": "tmmNNSGyDIl5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}